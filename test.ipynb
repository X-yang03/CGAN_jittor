{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zxy08\\.cache\\jittor\\jtcuda\\cuda11.2_cudnn8_win\\bin\\nvcc.exe\n"
     ]
    }
   ],
   "source": [
    "import jittor as jt\n",
    "from jittor import init\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "from jittor import nn\n",
    "\n",
    "if jt.has_cuda:\n",
    "    jt.flags.use_cuda = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.argv = ['run.py']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(n_epochs=100, batch_size=64, lr=0.0002, b1=0.5, b2=0.999, n_cpu=8, latent_dim=100, n_classes=10, img_size=32, channels=1, sample_interval=1000)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--n_epochs', type=int, default=100, help='number of epochs of training')\n",
    "parser.add_argument('--batch_size', type=int, default=64, help='size of the batches')\n",
    "parser.add_argument('--lr', type=float, default=0.0002, help='adam: learning rate')\n",
    "parser.add_argument('--b1', type=float, default=0.5, help='adam: decay of first order momentum of gradient')\n",
    "parser.add_argument('--b2', type=float, default=0.999, help='adam: decay of first order momentum of gradient')\n",
    "parser.add_argument('--n_cpu', type=int, default=8, help='number of cpu threads to use during batch generation')\n",
    "parser.add_argument('--latent_dim', type=int, default=100, help='dimensionality of the latent space')\n",
    "parser.add_argument('--n_classes', type=int, default=10, help='number of classes for dataset')\n",
    "parser.add_argument('--img_size', type=int, default=32, help='size of each image dimension')\n",
    "parser.add_argument('--channels', type=int, default=1, help='number of image channels')\n",
    "parser.add_argument('--sample_interval', type=int, default=1000, help='interval between image sampling')\n",
    "opt = parser.parse_args()\n",
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = (opt.channels, opt.img_size, opt.img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.label_emb = nn.Embedding(opt.n_classes, opt.n_classes)\n",
    "        # nn.Linear(in_dim, out_dim)表示全连接层\n",
    "        # in_dim：输入向量维度\n",
    "        # out_dim：输出向量维度\n",
    "        def block(in_feat, out_feat, normalize=True):  #用于定义一个层\n",
    "            layers = [nn.Linear(in_feat, out_feat)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat, 0.8))# 0.8是momentum参数，控制均值和方差的移动平均值的权重\n",
    "            layers.append(nn.LeakyReLU(0.2)) #激活函数是ReLu的变种，当输入小于0时，Leaky ReLU会乘以0.2，而不是直接输出0\n",
    "            return layers\n",
    "        self.model = nn.Sequential(*block((opt.latent_dim + opt.n_classes), 128, normalize=False), \n",
    "                                   *block(128, 256), \n",
    "                                   *block(256, 512), \n",
    "                                   *block(512, 1024), \n",
    "                                   nn.Linear(1024, int(np.prod(img_shape))), \n",
    "                                   nn.Tanh())\n",
    "\n",
    "    def execute(self, noise, labels):\n",
    "        gen_input = jt.contrib.concat((self.label_emb(labels), noise), dim=1)\n",
    "        img = self.model(gen_input)\n",
    "        # 将img从1024维向量变为32*32矩阵\n",
    "        img = img.view((img.shape[0], *img_shape))\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = nn.Embedding(opt.n_classes, opt.n_classes*opt.n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = jt.int32([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = test(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,100,]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = jt.array(np.random.normal(0, 1, (64, opt.latent_dim))).float32() #随机的噪声\n",
    "gen_labels = jt.array(np.random.randint(0, opt.n_classes, 64)).float32()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[64,]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = test(gen_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[64,100,]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = jt.contrib.concat((label,z), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[64,200,]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "em = nn.Embedding(opt.n_classes, opt.img_size * opt.img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.label_embedding = nn.Embedding(opt.n_classes, opt.n_classes)\n",
    "        self.model = nn.Sequential(nn.Linear((opt.n_classes + int(np.prod(img_shape))), 512), \n",
    "                                   nn.LeakyReLU(0.2), \n",
    "                                   nn.Linear(512, 512), \n",
    "                                   nn.Dropout(0.4), \n",
    "                                   nn.LeakyReLU(0.2), \n",
    "                                   nn.Linear(512, 512), \n",
    "                                   nn.Dropout(0.4), \n",
    "                                   nn.LeakyReLU(0.2), \n",
    "                                   # TODO: 添加最后一个线性层，最终输出为一个实数\n",
    "                                   nn.Linear(512, 1)\n",
    "                                   )\n",
    "\n",
    "    def execute(self, img, labels):\n",
    "        d_in = jt.contrib.concat((img.view((img.shape[0], (- 1))), self.label_embedding(labels)), dim=1)\n",
    "        # TODO: 将d_in输入到模型中并返回计算结果\n",
    "        validity = self.model(d_in)\n",
    "        return validity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 损失函数：平方误差\n",
    "# 调用方法：adversarial_loss(网络输出A, 分类标签B)\n",
    "# 计算结果：(A-B)^2\n",
    "adversarial_loss = nn.MSELoss()\n",
    "\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "# 导入MNIST数据集\n",
    "from jittor.dataset.mnist import MNIST\n",
    "import jittor.transform as transform\n",
    "transform = transform.Compose([\n",
    "    transform.Resize(opt.img_size),\n",
    "    transform.Gray(),\n",
    "    transform.ImageNormalize(mean=[0.5], std=[0.5]),\n",
    "])\n",
    "dataloader = MNIST(train=True, transform=transform).set_attrs(batch_size=opt.batch_size, shuffle=True)\n",
    "\n",
    "optimizer_G = nn.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
    "optimizer_D = nn.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64,1,32,32,]\n",
      "[64,1,32,32,]\n",
      "[64,2,32,32,]\n"
     ]
    }
   ],
   "source": [
    "for i, (imgs, labels) in enumerate(dataloader):\n",
    "    real_imgs = jt.array(imgs)\n",
    "    labels = jt.array(labels)\n",
    "    print(real_imgs.shape)\n",
    "    t1 = em(labels)\n",
    "    t1 = t1.reshape(t1.shape[0], 1, opt.img_size, opt.img_size)\n",
    "    print(t1.shape)\n",
    "    t2 = jt.contrib.concat((t1, real_imgs), dim=1)\n",
    "    print(t2.shape)\n",
    "    # print(real_imgs[0][0][0])\n",
    "    # print(t1[0][0][0])\n",
    "    # print(t2[0][0][0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1 = nn.Linear((opt.n_classes + int(np.prod(img_shape))), 1024)\n",
    "C1 = nn.Conv(1,6,5,1) # 6*28*28\n",
    "P1 = nn.Pool(2,2) # 6*14*14\n",
    "C2 = nn.Conv(6,16,5,1) # 16*10*10\n",
    "P2 = nn.Pool(2,2) # 16*5*5\n",
    "L2 = nn.Linear(16*5*5, 120)\n",
    "L3 = nn.Linear(120, 84)\n",
    "L4 = nn.Linear(84, 10)\n",
    "embed = nn.Embedding(opt.n_classes, opt.n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def execute(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "    \n",
    "class Reshape(nn.Module):\n",
    "    def execute(self, x):\n",
    "        return x.view(x.size(0), 1, 32, 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear((opt.n_classes + int(np.prod(img_shape))), 1024), #输入维度为图像向量维度+类别数（即label）\n",
    "                                   nn.LeakyReLU(0.2), #激活函数，当输入小于0时，Leaky ReLU会乘以0.2，而不是直接输出0\n",
    "                                   Reshape(), #将1024维的向量重新构建成32*32的图像矩阵\n",
    "                                   nn.Conv(1,6,5,1), # 6*28*28\n",
    "                                   nn.LeakyReLU(0.2),\n",
    "                                   nn.Pool(2,2), #  6*14*14\n",
    "                                   nn.Conv(6,16,5,1), # 16*10*\n",
    "                                   nn.LeakyReLU(0.2),\n",
    "                                   nn.Pool(2,2), # 16*5*5\n",
    "                                   Flatten(), #将图像矩阵展平\n",
    "                                   nn.Linear(16*5*5, 120),\n",
    "                                   nn.LeakyReLU(0.2),\n",
    "                                   nn.Linear(120, 84),\n",
    "                                   nn.LeakyReLU(0.2),\n",
    "                                   nn.Linear(84, 1),\n",
    "                                   nn.Sigmoid() #归一\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64,1,32,32,] [64,]\n",
      "[64,1024,]\n",
      "[64,1034,]\n",
      "[64,1,]\n",
      "jt.Var([[0.4775455 ]\n",
      "        [0.47970298]\n",
      "        [0.47715354]\n",
      "        [0.47776645]\n",
      "        [0.47834095]\n",
      "        [0.47867146]\n",
      "        [0.477492  ]\n",
      "        [0.47901678]\n",
      "        [0.478849  ]\n",
      "        [0.47909257]\n",
      "        [0.47740248]\n",
      "        [0.47768167]\n",
      "        [0.47900912]\n",
      "        [0.47804525]\n",
      "        [0.48083615]\n",
      "        [0.47759145]\n",
      "        [0.4801024 ]\n",
      "        [0.47777668]\n",
      "        [0.48016527]\n",
      "        [0.4768419 ]\n",
      "        [0.47751984]\n",
      "        [0.47815806]\n",
      "        [0.47764587]\n",
      "        [0.4784174 ]\n",
      "        [0.47830474]\n",
      "        [0.4789069 ]\n",
      "        [0.47900996]\n",
      "        [0.4758968 ]\n",
      "        [0.47781575]\n",
      "        [0.47745427]\n",
      "        [0.4766364 ]\n",
      "        [0.47958088]\n",
      "        [0.47970286]\n",
      "        [0.4796728 ]\n",
      "        [0.47823134]\n",
      "        [0.47699866]\n",
      "        [0.47812012]\n",
      "        [0.47939122]\n",
      "        [0.47638866]\n",
      "        [0.47748902]\n",
      "        [0.4782316 ]\n",
      "        [0.47879985]\n",
      "        [0.47901782]\n",
      "        [0.47712362]\n",
      "        [0.47959754]\n",
      "        [0.47825456]\n",
      "        [0.4790367 ]\n",
      "        [0.47976223]\n",
      "        [0.4786911 ]\n",
      "        [0.47839344]\n",
      "        [0.4775416 ]\n",
      "        [0.47764054]\n",
      "        [0.47919488]\n",
      "        [0.47943923]\n",
      "        [0.47956428]\n",
      "        [0.47906122]\n",
      "        [0.47661376]\n",
      "        [0.47710213]\n",
      "        [0.4788297 ]\n",
      "        [0.47758573]\n",
      "        [0.47697723]\n",
      "        [0.4785179 ]\n",
      "        [0.47742504]\n",
      "        [0.48000696]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for i, (imgs, labels) in enumerate(dataloader):\n",
    "    batch_size = imgs.shape[0] #64\n",
    "\n",
    "    print(imgs.shape, labels.shape)\n",
    "\n",
    "    print(imgs.view((imgs.shape[0], (- 1))).shape)\n",
    "\n",
    "    d_in = jt.contrib.concat((imgs.view((imgs.shape[0], (- 1))), embed(labels)), dim=1)\n",
    "    print(d_in.shape)\n",
    "\n",
    "    t8 = model(d_in)\n",
    "    print(t8.shape)\n",
    "    print(t8)\n",
    "\n",
    "    # 数据标签，valid=1表示真实的图片，fake=0表示生成的图片\n",
    "    valid = jt.ones([batch_size, 1]).float32().stop_grad()\n",
    "    fake = jt.zeros([batch_size, 1]).float32().stop_grad()\n",
    "\n",
    "    if i==0:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jittor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
